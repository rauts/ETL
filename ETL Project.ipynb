{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract, Transform, and Load (ETL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I will show you a complete ETL steps to create a data warehouse using UK customers data. To perform ETL steps, I will be using Microsoft SQL Server Integration Service (SSIS) software. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A raw customer dataset in `.csv` format is provided that includes 17 variables such as `Name`, `Address`, `ZIP Code`, , `Email`, `Birth Date`, `Credit Card Provider`, `Credit Card Number` ..., `BloodType`, `Kilograms`, and `Centimeters`. Of course, these variables are made up. A company wants to analyse three biological variables in the dataset: \n",
    "\n",
    "   - BloodType\n",
    "   - Kilograms\n",
    "   - Centimeters\n",
    "\n",
    " and as a data scientist, your task are to extract records that must include these three variables among others, to record any anamalies in the dataset and to load the good records in the database for further analyses. \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are several steps that need to performed during ETL process and I will walk you through these steps in the next section.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **Open Microsoft Visual Studio 2019 and create an Integration Service Project for data warehouse.**\n",
    " \n",
    " A screenshot of creating an Integration Service Project in Microsoft Visual Studio 2019 is shown in the figure below where Integration Service Project is encircled in red. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"./images/open_integration_proejct_MsVisualStudio.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the `Step 1` is shown in the figure below.\n",
    "\n",
    "<img src=\"./images/1_controlFlow.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "   - **Drag and drop the `Data Flow Task` icon from the `Favorites` dropdown menu on the left (in SSIS Toolbox) to the `Control Flow` window as shown below.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/drag&drop_dataFlowTask.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "    \n",
    "   - Click on `Data Flow` icon \n",
    "    \n",
    "    \n",
    "The resulting view looks like this. Notice the changes in the SSIS Toolbox on the left encircled in red. There are more tools. Next, we will be using some of them.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/dataFlowWindow2.PNG\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "\n",
    "Now, we are ready to add and configure connfection managers for Flat File Source, Flat File Destinations and a Database in the SSIS package.\n",
    "\n",
    "   - **Drag and drop `Flat File Source` from `Other Sources` dropdown menu on the left to the SSIS package on the right.** \n",
    "\n",
    "The resulting figure looks like this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/add_flatfilesource.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **next add `Flat File Destination` from `Other Destinations` menu on the left, as shown below.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/add_flatfiledestination.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - **add `Conditional Split` block from the `Other Transforms` menu on the left. This block is used to split the data into two parts based on some logics.** \n",
    "   \n",
    "Remember, in our task for data warehouse, we need to fullfill the criterion that the dataset must have three variables. Such type of condition can be implemented using this `Conditional Split` block, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/add_conditionalsplit.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **finally, add an SQL database as a destination where good records are saved. The figure looks like this.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/add_databasedestination.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that, I created two conditional splits to fulfill the requriements for the good records for data warehouse and two flat file destionations to records different types of bad records or corrupted data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **Open Microsoft SQL Server Management Studio where good records will be saved.**\n",
    " \n",
    "SQL server looks like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/7_connecting2SQLserver.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pressing the connect button, the next window would open. Then, I created an empty database called `Project_DataBase` incircled in red. Note that there is not any table in that database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/open_database.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, SQL Server is connected. Let us view both SQL Server and SSIS package in the same window as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/serverandssispackage_inthesamewindow.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I had already set up connection managers for source file and two destinations, encircled in red in the above figure bottm right. Now, we only need to create a connection manager for Database that we will show you in next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - **Setup a database connection manager to connect Microsoft SQL Server and SSIS package to store good records.**\n",
    "   \n",
    "In order to connect the SSIS package and SQL server, double click on `Database` block and the following window will be opened. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/10_select_serverEngine_and_ProjectDatabase.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, select the name of the database, `Project_Database` and click OK. Next, we need to create a table where we want to store variables. Let us look at how a table is created in Microsoft SQL in the following figure. Notice that the name of the table is `RAW_CustomersUK_20200221`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/createTableUsingSQL.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now select the name of the table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/selectTableName.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then click on mapplings and OK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/mappingtable.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that a conection manager has been established, encircled in red on the bottom where other connection managers are located."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/dbconnection.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7\n",
    "\n",
    "      \n",
    "   - **Press Start button to start the ELT process.**\n",
    "     \n",
    "Once the start button is pressed, the ETL process starts and window looks like this.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/start_ETL1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the left, you see that the table `dbo.RAW_CustomersUK_20200221` has been created on the database `Project_Database`and on the right, we can see that the ELT process is running; **13356** rows have been read from the source. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When all the data has been read from the source file, the window looks like as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/elt_finish.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total $99,997$ rows were read from the source among them $261$ records are stored in an Infficient Records file, $99731$ records are stored in the Database table `dbo.RAW_CustomersUK_20200221` and $5$ records are stored in the bad records.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8\n",
    "\n",
    "   - **Check Quality assurance**\n",
    "\n",
    "To check the quality of the data stored in the datbase table, we use SQL queries and shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img str=\"./images/QAafterETL1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/QAafterELT1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The table output look good!. Let us check the total rows in the table.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/QA_final.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number $99731$ in the table is exactely the same as the total rows recorded in the database on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The ELT process ends here.**\n",
    "\n",
    "**The original file and the processed data are can be found in the folder `20200221_NamesUK`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
